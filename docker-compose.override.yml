#
# Dramatiq services environment variables anchor
x-dramatiq-env: &dramatiq_env
  # Redis configuration for Dramatiq workers ONLY
  REDIS_HOST: "redis"
  REDIS_PORT: "6379"
  REDIS_DB: "0"
  # MinIO access for file operations
  STORAGE_ENDPOINT: "http://minio:9000"
  MINIO_PUBLIC_ENDPOINT: "http://storage.${DOMAIN?Variable not set}"
  STORAGE_ACCESS_KEY: "${MINIO_ROOT_USER:-minio}"
  STORAGE_SECRET_KEY: "${MINIO_ROOT_PASSWORD:-password}"

# Dispatcher environment variables (still uses Kafka)
x-dispatcher-env: &dispatcher_env
  KAFKA_BOOTSTRAP: "kafka:9092"
  MINIO_TOPIC: ${MINIO_TOPIC:-minio.uploads} # Used by dispatcher
  STORAGE_ENDPOINT: "http://minio:9000"
  MINIO_PUBLIC_ENDPOINT: "http://storage.${DOMAIN?Variable not set}"
  STORAGE_ACCESS_KEY: "${MINIO_ROOT_USER:-minio}"
  STORAGE_SECRET_KEY: "${MINIO_ROOT_PASSWORD:-password}"
  # Kafka configuration parameters for dispatcher
  DRAMATIQ_GROUP_ID: "${DRAMATIQ_GROUP_ID:-tts-workers}"
  DRAMATIQ_MAX_POLL_RECORDS: "${DRAMATIQ_MAX_POLL_RECORDS:-32}"
  DRAMATIQ_AUTO_OFFSET_RESET: "${DRAMATIQ_AUTO_OFFSET_RESET:-earliest}"
  KAFKA_MAX_POLL_RECORDS: "${KAFKA_MAX_POLL_RECORDS:-32}"
  KAFKA_AUTO_OFFSET_RESET: "${KAFKA_AUTO_OFFSET_RESET:-earliest}"
  # Topic names for Kafka
  MINIO_NOTIFY_KAFKA_TOPIC_PRIMARY: ${MINIO_TOPIC:-minio.uploads}
  MINIO_NOTIFY_KAFKA_TOPIC_SECONDARY: ${MINIO_TOPIC:-minio.uploads.segments}
  MINIO_NOTIFY_KAFKA_TOPIC_TERTIARY: ${MINIO_TOPIC:-minio.uploads.transcripts}
services:
  # Local services are available on their ports, but also available on:
  # http://api.localhost.tiangolo.com: backend
  # http://dashboard.localhost.tiangolo.com: frontend
  # etc. To enable it, update .env, set:
  # DOMAIN=localhost.tiangolo.com
  proxy:
    image: traefik:3.0
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "80:80"
      - "8090:8080"
    # Duplicate the command from docker-compose.yml to add --api.insecure=true
    command:
      # Enable Docker in Traefik, so that it reads labels from Docker services
      - --providers.docker
      # Add a constraint to only use services with the label for this stack
      - --providers.docker.constraints=Label(`traefik.constraint-label`, `traefik-public`)
      # Do not expose all Docker services, only the ones explicitly exposed
      - --providers.docker.exposedbydefault=false
      # Create an entrypoint "http" listening on port 80
      - --entrypoints.http.address=:80
      # Create an entrypoint "https" listening on port 443
      - --entrypoints.https.address=:443
      # Enable the access log, with HTTP requests
      - --accesslog
      # Enable the Traefik log, for configurations and errors
      - --log
      # Enable debug logging for local development
      - --log.level=DEBUG
      # Enable the Dashboard and API
      - --api
      # Enable the Dashboard and API in insecure mode for local development
      - --api.insecure=true
    labels:
      # Enable Traefik for this service, to make it available in the public network
      - traefik.enable=true
      - traefik.constraint-label=traefik-public
      # Dummy https-redirect middleware that doesn't really redirect, only to
      # allow running it locally
      - traefik.http.middlewares.https-redirect.contenttype.autodetect=false
    networks:
      - traefik-public
      - default
    depends_on:
      db:
        condition: service_started
      minio:
        condition: service_started
      kafka:
        condition: service_started

  db:
    restart: "no"
    ports:
      - "5432:5432"

  adminer:
    restart: "no"
    ports:
      - "8080:8080"

  backend:
    restart: "no"
    ports:
      - "8000:8000"
    build:
      context: ./backend
    # command: sleep infinity  # Infinite loop to keep container alive doing nothing
    command:
      - fastapi
      - run
      - --reload
      - "app/main.py"
    develop:
      watch:
        - path: ./backend
          action: sync
          target: /app
          ignore:
            - ./backend/.venv
            - .venv
        - path: ./backend/pyproject.toml
          action: rebuild
    # TODO: remove once coverage is done locally
    volumes:
      - ./backend/htmlcov:/app/htmlcov
    environment:
      SMTP_HOST: "mailcatcher"
      SMTP_PORT: "1025"
      SMTP_TLS: "false"
      EMAILS_FROM_EMAIL: "noreply@example.com"
      MINIO_URL_INTERNAL: "http://minio:9000"
      STORAGE_ENDPOINT: "http://minio:9000" # Internal endpoint for SDK
      MINIO_PUBLIC_ENDPOINT: "http://storage.${DOMAIN?Variable not set}" # Public endpoint, requires DOMAIN
      STORAGE_ACCESS_KEY: "${MINIO_ROOT_USER:-minio}"
      STORAGE_SECRET_KEY: "${MINIO_ROOT_PASSWORD:-password}"
    depends_on:
      db:
        condition: service_started
      minio:
        condition: service_started
      kafka:
        condition: service_healthy

  mailcatcher:
    image: schickling/mailcatcher
    ports:
      - "1080:1080"
      - "1025:1025"

  frontend:
    restart: "no"
    ports:
      - "5173:80"
    build:
      context: ./frontend
      args:
        - VITE_API_URL=http://localhost:8000
        - NODE_ENV=development
        - VITE_UPLOAD_ENDPOINT=http://storage.${DOMAIN?Variable not set}
    environment:
      - VITE_API_URL=http://localhost:8000
      - NODE_ENV=development
      - VITE_UPLOAD_ENDPOINT=http://storage.${DOMAIN?Variable not set}
    depends_on:
      backend:
        condition: service_started
      minio:
        condition: service_started

  prestart:
    environment:
      - MINIO_URL_INTERNAL=http://minio:9000
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - FRONTEND_ORIGIN=http://dashboard.${DOMAIN?Variable not set} # Example
      - MINIO_PRIMARY_BUCKET=uploads
      - MINIO_SECONDARY_BUCKET=segments
      - MINIO_TERTIARY_BUCKET=transcripts
      - MINIO_NOTIFY_KAFKA_TOPIC_PRIMARY=${MINIO_TOPIC:-minio.uploads}
      - MINIO_KAFKA_NOTIFICATION_ARN=arn:minio:sqs::PRIMARY:kafka
    depends_on:
      db:
        condition: service_healthy
      minio:
        condition: service_healthy

  playwright:
    build:
      context: ./frontend
      dockerfile: Dockerfile.playwright
      args:
        - VITE_API_URL=http://backend:8000
        - NODE_ENV=production
    ipc: host
    depends_on:
      - backend
      - mailcatcher
    env_file:
      - .env
    environment:
      - VITE_API_URL=http://backend:8000
      - MAILCATCHER_HOST=http://mailcatcher:1080
      # For the reports when run locally
      - PLAYWRIGHT_HTML_HOST=0.0.0.0
      - CI=${CI}
    volumes:
      - ./frontend/blob-report:/app/blob-report
      - ./frontend/test-results:/app/test-results
    ports:
      - 9323:9323

  kafka:
    image: bitnami/kafka:latest
    ports:
      - "9092:9092"
    environment:
      - KAFKA_KRAFT_CLUSTER_ID=dev-cluster
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_BOOTSTRAP=kafka:9092
      - KAFKA_MAX_POLL_RECORDS=32
      - KAFKA_AUTO_OFFSET_RESET=earliest
      - MINIO_NOTIFY_KAFKA_TOPIC_PRIMARY=minio.uploads
      - MINIO_NOTIFY_KAFKA_TOPIC_SECONDARY=minio.uploads.segments
      - MINIO_NOTIFY_KAFKA_TOPIC_TERTIARY=minio.uploads.transcripts
    networks:
      - default
      - traefik-public
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 10s
      timeout: 5s
      retries: 10

  kafdrop:
    image: obsidiandynamics/kafdrop:latest
    restart: "no" # Consistent with other local services
    ports:
      - "9002:9000" # Host port 9002, Kafdrop internal port 9000
    environment:
      KAFKA_BROKERCONNECT: "kafka:9092" # Connects to your existing kafka service
      JVM_OPTS: "-Xms32M -Xmx64M" # Optional: To keep resource usage low for dev
    depends_on:
      kafka:
        condition: service_started
    networks:
      - default
      - traefik-public
    labels:
      - "traefik.enable=true"
      - "traefik.docker.network=traefik-public"
      - "traefik.constraint-label=traefik-public"
      - "traefik.http.routers.kafdrop-http.rule=Host(`kafka-ui.${DOMAIN?Variable not set}`)"
      - "traefik.http.routers.kafdrop-http.entrypoints=http"
      - "traefik.http.services.kafdrop-http.loadbalancer.server.port=9000" # Kafdrop's internal port
      # Use the dummy https-redirect from the local proxy service
      - "traefik.http.routers.kafdrop-http.middlewares=https-redirect"

  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000" # S3 API
      - "9001:9001" # web console
    volumes:
      - "miniodata:/data"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-password}
      MINIO_API_CORS_ALLOW_ORIGIN: "http://localhost:5173,http://dashboard.${DOMAIN?Variable not set}"
      MINIO_NOTIFY_KAFKA_ENABLE_PRIMARY: "on"
      MINIO_NOTIFY_KAFKA_BROKERS_PRIMARY: "kafka:9092"
      MINIO_NOTIFY_KAFKA_TOPIC_PRIMARY: ${MINIO_TOPIC:-minio.uploads}
      MINIO_NOTIFY_KAFKA_TOPIC_SECONDARY: ${MINIO_TOPIC:-minio.uploads.segments}
      MINIO_NOTIFY_KAFKA_TOPIC_TERTIARY: ${MINIO_TOPIC:-minio.uploads.transcripts}
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "/usr/bin/mc", "ready", "local"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 5s
    networks:
      - default
      - traefik-public
    labels:
      - "traefik.enable=true"
      - "traefik.docker.network=traefik-public"
      - "traefik.constraint-label=traefik-public"
      # HTTP router for MinIO API (port 9000)
      - "traefik.http.routers.minio-s3-http.rule=Host(`storage.${DOMAIN?Variable not set}`)"
      - "traefik.http.routers.minio-s3-http.entrypoints=http"
      - "traefik.http.routers.minio-s3-http.service=minio-s3"
      - "traefik.http.services.minio-s3.loadbalancer.server.port=9000"
      # HTTP router for MinIO Console (port 9001)
      - "traefik.http.routers.minio-console-http.rule=Host(`minio-console.${DOMAIN?Variable not set}`)"
      - "traefik.http.routers.minio-console-http.entrypoints=http"
      - "traefik.http.routers.minio-console-http.service=minio-console"
      - "traefik.http.services.minio-console.loadbalancer.server.port=9001"
      # Apply dummy https-redirect if consistent with local proxy setup
      - "traefik.http.routers.minio-s3-http.middlewares=https-redirect"
      - "traefik.http.routers.minio-console-http.middlewares=https-redirect"

  clamav:
    image: mkodockx/docker-clamav:alpine
    volumes:
      - "clamcache:/var/lib/clamav"

  redis:
    image: redis:alpine
    restart: "no"
    ports:
      - "6379:6379"
    volumes:
      - "redis-data:/data"
    networks:
      - default

  # New Dramatiq services
  # dispatcher:
  #   build:
  #     context: ./backend # Ensure this is the intended build context
  #     dockerfile: docker/Dockerfile.cpu # Path relative to new context
  #   command: "python -m app.task_orchestration.pipe.dispatcher" # MODIFIED
  #   environment: *dispatcher_env
  #   depends_on:
  #     kafka:
  #       condition: service_started
  #     minio:
  #       condition: service_started # Dispatcher reads from MinIO, so it needs MinIO to be up.
  #   restart: "no"
  #   networks:
  #     - default

  worker-convert:
    build:
      context: ./backend # Ensure this is the intended build context
      dockerfile: docker/Dockerfile.cpu # Path relative to new context
    command: "dramatiq app.tasks.pipeline_tasks --processes 4 --queues convert_cpu" # MODIFIED
    environment: *dramatiq_env
    depends_on:
      redis:
        condition: service_started
      minio: # Actors use MinIO via utils
        condition: service_started
    restart: "no"
    networks:
      - default

  worker-split:
    build:
      context: ./backend # Ensure this is the intended build context
      dockerfile: docker/Dockerfile.cpu # Path relative to new context
    command: "dramatiq app.tasks.pipeline_tasks --processes 4 --queues split_cpu" # MODIFIED
    environment: *dramatiq_env
    depends_on:
      redis:
        condition: service_started
      minio:
        condition: service_started
    restart: "no"
    networks:
      - default

  worker-transcribe-cpu:
    build:
      context: ./backend # Ensure this is the intended build context
      dockerfile: docker/Dockerfile.cpu # Path relative to new context
    command: "dramatiq app.tasks.pipeline_tasks --processes 2 --queues transcribe_cpu" # MODIFIED
    environment: *dramatiq_env
    profiles: ["cpu"]
    depends_on:
      redis:
        condition: service_started
      minio:
        condition: service_started
    restart: "no"
    networks:
      - default

  worker-transcribe-cuda:
    build:
      context: ./backend # Ensure this is the intended build context
      dockerfile: docker/Dockerfile.cuda # Path relative to new context
    command: "dramatiq app.tasks.pipeline_tasks --processes 2 --queues transcribe_cuda" # MODIFIED
    environment:
      <<: *dramatiq_env
      NVIDIA_VISIBLE_DEVICES: "all"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: ["gpu"]
    profiles: ["cuda"]
    depends_on:
      redis:
        condition: service_started
      minio:
        condition: service_started
    restart: "no"
    runtime: nvidia
    networks:
      - default

  worker-transcribe-rocm: # Added back ROCm worker
    build:
      context: ./backend # Ensure this is the intended build context
      dockerfile: docker/Dockerfile.rocm # Path relative to new context
    command: "dramatiq app.tasks.pipeline_tasks --processes 2 --queues transcribe_rocm" # MODIFIED
    environment: *dramatiq_env
    devices:
      - /dev/kfd:/dev/kfd # Typical for ROCm
      - /dev/dri:/dev/dri # Typical for ROCm
    security_opt:
      - seccomp:unconfined # Often needed for GPU access
    profiles: ["rocm"]
    depends_on:
      redis:
        condition: service_started
      minio:
        condition: service_started
    restart: "no"
    networks:
      - default

  worker-final:
    build:
      context: ./backend # Ensure this is the intended build context
      dockerfile: docker/Dockerfile.cpu # Path relative to new context
    command: "dramatiq app.tasks.pipeline_tasks --processes 2 --queues final_cpu" # MODIFIED
    environment: *dramatiq_env
    depends_on:
      redis:
        condition: service_started
      minio:
        condition: service_started
    restart: "no"
    networks:
      - default


networks:
  traefik-public:
    # For local dev, don't expect an external Traefik network
    external: false

volumes:
  miniodata: {}
  clamcache: {}
  redis-data: {}
